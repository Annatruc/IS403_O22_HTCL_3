{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "96MC0GFNsC-Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rgPJ5TSsI3V",
        "outputId": "a60d16f3-24dd-4736-b4b7-cd8982cb1869"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "usd_data = pd.read_csv('/content/drive/MyDrive/dataset/us_dollar.csv', sep=',')\n",
        "bitcoin_data = pd.read_csv('/content/drive/MyDrive/dataset/bitcoin.csv', sep=',')\n",
        "nasdaq_data = pd.read_csv('/content/drive/MyDrive/dataset/nasdaq.csv', sep=',')"
      ],
      "metadata": {
        "id": "P4iHbFoasKfP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove commas from 'Price' column and convert to float\n",
        "nasdaq_data['Price'] = nasdaq_data['Price'].str.replace(',', '').astype(float)"
      ],
      "metadata": {
        "id": "_RGUcuJjsMhu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define preprocess_data function\n",
        "def preprocess_data(data, seq_length):\n",
        "    # Scaling data\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data[['Price']])\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data_scaled) - seq_length):\n",
        "        X.append(data_scaled[i:i+seq_length])\n",
        "        y.append(data_scaled[i+seq_length])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y, scaler"
      ],
      "metadata": {
        "id": "dztiKg83sOBD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data Function\n",
        "def split_data(X, y, train_ratio=0.7, val_ratio=0.2):\n",
        "    total_samples = len(X)\n",
        "    train_end = int(total_samples * train_ratio)\n",
        "    val_end = int(total_samples * (train_ratio + val_ratio))\n",
        "\n",
        "    X_train, y_train = X[:train_end], y[:train_end]\n",
        "    X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
        "    X_test, y_test = X[val_end:], y[val_end:]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "metadata": {
        "id": "GaUZ2WQgsP-U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "seq_length = 30"
      ],
      "metadata": {
        "id": "4VWSqxw9sSDK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USD Data\n",
        "X_usd, y_usd, usd_scaler = preprocess_data(usd_data, seq_length)\n",
        "X_train_usd, y_train_usd, X_val_usd, y_val_usd, X_test_usd, y_test_usd = split_data(X_usd, y_usd)\n",
        "\n",
        "# Bitcoin Data\n",
        "X_bitcoin, y_bitcoin, bitcoin_scaler = preprocess_data(bitcoin_data, seq_length)\n",
        "X_train_bitcoin, y_train_bitcoin, X_val_bitcoin, y_val_bitcoin, X_test_bitcoin, y_test_bitcoin = split_data(X_bitcoin, y_bitcoin)\n",
        "\n",
        "# Nasdaq Data\n",
        "X_nasdaq, y_nasdaq, nasdaq_scaler = preprocess_data(nasdaq_data, seq_length)\n",
        "X_train_nasdaq, y_train_nasdaq, X_val_nasdaq, y_val_nasdaq, X_test_nasdaq, y_test_nasdaq = split_data(X_nasdaq, y_nasdaq)"
      ],
      "metadata": {
        "id": "pgiNxGL1sTbc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch Tensors\n",
        "def to_tensors(X, y):\n",
        "    X_tensor = torch.from_numpy(X).float()\n",
        "    y_tensor = torch.from_numpy(y).float()\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "X_train_usd, y_train_usd = to_tensors(X_train_usd, y_train_usd)\n",
        "X_val_usd, y_val_usd = to_tensors(X_val_usd, y_val_usd)\n",
        "X_test_usd, y_test_usd = to_tensors(X_test_usd, y_test_usd)\n",
        "\n",
        "X_train_bitcoin, y_train_bitcoin = to_tensors(X_train_bitcoin, y_train_bitcoin)\n",
        "X_val_bitcoin, y_val_bitcoin = to_tensors(X_val_bitcoin, y_val_bitcoin)\n",
        "X_test_bitcoin, y_test_bitcoin = to_tensors(X_test_bitcoin, y_test_bitcoin)\n",
        "\n",
        "X_train_nasdaq, y_train_nasdaq = to_tensors(X_train_nasdaq, y_train_nasdaq)\n",
        "X_val_nasdaq, y_val_nasdaq = to_tensors(X_val_nasdaq, y_val_nasdaq)\n",
        "X_test_nasdaq, y_test_nasdaq = to_tensors(X_test_nasdaq, y_test_nasdaq)"
      ],
      "metadata": {
        "id": "bFfN-9i6sVmA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "def create_dataloader(X_train, y_train, X_val, y_val, X_test, y_test, batch_size=32):\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    val_dataset = TensorDataset(X_val, y_val)\n",
        "    test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "train_loader_usd, val_loader_usd, test_loader_usd = create_dataloader(X_train_usd, y_train_usd, X_val_usd, y_val_usd, X_test_usd, y_test_usd)\n",
        "train_loader_bitcoin, val_loader_bitcoin, test_loader_bitcoin = create_dataloader(X_train_bitcoin, y_train_bitcoin, X_val_bitcoin, y_val_bitcoin, X_test_bitcoin, y_test_bitcoin)\n",
        "train_loader_nasdaq, val_loader_nasdaq, test_loader_nasdaq = create_dataloader(X_train_nasdaq, y_train_nasdaq, X_val_nasdaq, y_val_nasdaq, X_test_nasdaq, y_test_nasdaq)"
      ],
      "metadata": {
        "id": "8RFvBiPZsXoP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])  # Use only the last time step's output\n",
        "        return out"
      ],
      "metadata": {
        "id": "ogk3jrz1sZk_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the training function for LSTM\n",
        "def train_lstm_model(model, train_loader, val_loader, num_epochs=10, lr=0.001):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                y_pred = model(X_batch)\n",
        "                val_loss += criterion(y_pred, y_batch).item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Val Loss: {val_loss/len(val_loader)}')"
      ],
      "metadata": {
        "id": "BLhGBhvisbqm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LSTM model on USD data\n",
        "input_size = X_train_usd.shape[2]\n",
        "output_size = 1\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "\n",
        "print(\"Training LSTM model on USD data\")\n",
        "lstm_model_usd = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "train_lstm_model(lstm_model_usd, train_loader_usd, val_loader_usd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s62aEEcztEee",
        "outputId": "c2e6d967-06f4-4255-d1c5-64cc47a7a6e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model on USD data\n",
            "Epoch 1, Train Loss: 0.019207824021577835, Val Loss: 0.047924858631126374\n",
            "Epoch 2, Train Loss: 0.001091514015570283, Val Loss: 0.009874849012703635\n",
            "Epoch 3, Train Loss: 0.0006551790283992887, Val Loss: 0.007317534482960279\n",
            "Epoch 4, Train Loss: 0.00047764883493073285, Val Loss: 0.006242897280672979\n",
            "Epoch 5, Train Loss: 0.0009234330500476062, Val Loss: 0.006103296938817948\n",
            "Epoch 6, Train Loss: 0.0011697725858539343, Val Loss: 0.00546141392907076\n",
            "Epoch 7, Train Loss: 0.0005005383864045143, Val Loss: 0.004697149815102521\n",
            "Epoch 8, Train Loss: 0.0008984467713162303, Val Loss: 0.0043678883392001605\n",
            "Epoch 9, Train Loss: 0.001421266933903098, Val Loss: 0.0038574353772370764\n",
            "Epoch 10, Train Loss: 0.0007410934194922447, Val Loss: 0.00348355468789426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict future values using the trained LSTM model\n",
        "def predict_future_lstm(model, X_val, scaler, predict_days=90):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for input_seq in X_val:\n",
        "            input_seq = input_seq.unsqueeze(0)  # Add batch dimension\n",
        "            predictions = []\n",
        "            for _ in range(predict_days):\n",
        "                next_pred = model(input_seq)\n",
        "                predictions.append(next_pred.item())\n",
        "                input_seq = torch.cat((input_seq[:, :, 1:], next_pred.unsqueeze(2)), dim=2)  # Slide window\n",
        "            all_predictions.extend(predictions)\n",
        "\n",
        "    all_predictions = scaler.inverse_transform(np.array(all_predictions).reshape(-1, 1))\n",
        "    return all_predictions\n",
        "\n",
        "predictions_usd_lstm = predict_future_lstm(lstm_model_usd, X_val_usd, usd_scaler)\n",
        "plot_results(usd_data, predictions_usd_lstm, 'Actual vs. Predicted USD Index (LSTM)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "RfEXBQGMtGsr",
        "outputId": "b9d568c5-2ced-4b53-fe3c-b3956525c5c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 2. Expected size 30 but got size 1 for tensor number 1 in the list.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d4884dfc9eb3>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpredictions_usd_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_future_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model_usd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_usd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musd_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musd_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_usd_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Actual vs. Predicted USD Index (LSTM)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-d4884dfc9eb3>\u001b[0m in \u001b[0;36mpredict_future_lstm\u001b[0;34m(model, X_val, scaler, predict_days)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mnext_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Slide window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 30 but got size 1 for tensor number 1 in the list."
          ]
        }
      ]
    }
  ]
}